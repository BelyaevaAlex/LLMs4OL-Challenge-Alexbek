#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ—Ä–º–∏–Ω–æ–≤ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
–î–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ conda –æ–∫—Ä—É–∂–µ–Ω–∏–∏ (rah_11_cu12.4_torch)
"""

import os
import json
from term_classification_with_embeddings import EmbeddingTermClassifier

def load_json_data(file_path):
    with open(file_path, 'r') as f:
        return json.load(f)

def get_domain_files(domain, base_path):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞"""
    domain_lower = domain.lower()
    train_file = os.path.join(base_path, domain, "train", "term_typing_train_data.json")
    test_file = os.path.join(base_path, domain, "test", f"{domain_lower}_term_typing_test_data.json")
    return train_file, test_file

def main():
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    base_path = "../../../2025/TaskB-TermTyping"
    domains = ["MatOnto", "OBI", "SWEET"]
    
    for domain in domains:
        print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–º–µ–Ω–∞ {domain}")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –¥–∞–Ω–Ω—ã—Ö
        train_file, test_file = get_domain_files(domain, base_path)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        train_data = load_json_data(train_file)
        test_data = load_json_data(test_file)
        
        print(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(train_data)}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(test_data)}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        save_dir = f"predictions_embedding_{domain}"
        os.makedirs(save_dir, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        classifier = EmbeddingTermClassifier()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X_train_embeddings, y_train, X_test_embeddings, test_terms = classifier.prepare_data(train_data, test_data)
        
        # –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        clf, clf_with_graph, G = classifier.train_and_evaluate(domain, save_dir)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        predictions, predictions_with_graph = classifier.predict(
            clf, clf_with_graph, G, X_test_embeddings, test_terms, test_data, save_dir
        )
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–º–µ–Ω–∞ {domain} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {save_dir}")

if __name__ == "__main__":
    main() 