#!/usr/bin/env python3
"""
Meta-Model Training Script - Simplified version for training only Meta-Model

This script provides:
- Training Meta-Model from scratch
- Automatic determination of optimal F1 threshold
- Flexible Qwen3 freezing
- Complete metrics and monitoring system

Usage example:
    python train_meta_model.py \
        --terms_path data/terms.txt \
        --relations_path data/relations.json \
        --output_dir experiments/new_approach \
        --dataset_name DATASET_NAME \
        --freeze_strategy except_last
"""

import sys
import os
import argparse
import json
import logging
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Tuple

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
import numpy as np
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split

# Matplotlib setup for server environment
import matplotlib
matplotlib.use('Agg')  # Use backend without GUI
import matplotlib.pyplot as plt

# Wandb for logging
try:
    import wandb
    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False
    print("‚ö†Ô∏è wandb not found. Install: pip install wandb")

from meta_model import Qwen3CrossAttentionMetaModel, create_meta_model_from_scratch
from dataset import MetaModelDataset


def setup_logging(log_dir: str, log_level: str = "INFO") -> logging.Logger:
    """Setup logging to file and console"""
    os.makedirs(log_dir, exist_ok=True)
    
    logger = logging.getLogger("meta_model_training")
    logger.setLevel(getattr(logging, log_level.upper()))
    logger.handlers.clear()
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Handler for file
    log_file = os.path.join(log_dir, f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    
    # Handler for console
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    logger.info(f"Logging configured. Log file: {log_file}")
    return logger


def apply_freeze_strategy(model: Qwen3CrossAttentionMetaModel, freeze_strategy: str, lora_rank: int = 8, lora_alpha: int = 16):
    """
    Apply weight freezing strategy
    
    Args:
        model: meta-model
        freeze_strategy: freezing strategy ("full", "except_last", "lora", "none")
        lora_rank: rank for LORA adapter
        lora_alpha: alpha for LORA adapter
    """
    logger = logging.getLogger("meta_model_training")
    
    if freeze_strategy == "full":
        # Full Qwen3 freezing
        logger.info("üßä Applying full Qwen3 freezing")
        for param in model.qwen3_model.parameters():
            param.requires_grad = False
        
    elif freeze_strategy == "except_last":
        # Freeze all layers except the last one
        logger.info("üßä Applying Qwen3 freezing except last layer")
        for param in model.qwen3_model.parameters():
            param.requires_grad = False
        
        # Unfreeze the last layer
        if hasattr(model.qwen3_model, 'layers') and model.qwen3_model.layers:
            last_layer = model.qwen3_model.layers[-1]
            for param in last_layer.parameters():
                param.requires_grad = True
            logger.info(f"‚úÖ Last layer ({len(model.qwen3_model.layers)-1}) unfrozen")
        
        # Also unfreeze layer norm if exists
        if hasattr(model.qwen3_model, 'norm'):
            for param in model.qwen3_model.norm.parameters():
                param.requires_grad = True
            logger.info("‚úÖ Final layer norm unfrozen")
    
    elif freeze_strategy == "lora":
        # Freeze base weights + add LORA adapters
        logger.info(f"üßä Applying LORA adapter (rank={lora_rank}, alpha={lora_alpha})")
        
        try:
            from peft import LoraConfig, get_peft_model, TaskType
            
            # Freeze all base weights
            for param in model.qwen3_model.parameters():
                param.requires_grad = False
            
            # LORA configuration
            lora_config = LoraConfig(
                task_type=TaskType.FEATURE_EXTRACTION,
                r=lora_rank,
                lora_alpha=lora_alpha,
                target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
                lora_dropout=0.1,
            )
            
            # Apply LORA to model
            model.qwen3_model = get_peft_model(model.qwen3_model, lora_config)
            logger.info(f"‚úÖ LORA adapter applied successfully")
            
        except ImportError:
            logger.warning("‚ö†Ô∏è PEFT library not found. Install: pip install peft")
            logger.info("üîÑ Switching to 'except_last' strategy")
            apply_freeze_strategy(model, "except_last", lora_rank, lora_alpha)
            return
    
    elif freeze_strategy == "none":
        # No freezing - train all weights
        logger.info("üî• No freezing - training all Qwen3 weights")
        for param in model.qwen3_model.parameters():
            param.requires_grad = True
    
    else:
        raise ValueError(f"Unknown freezing strategy: {freeze_strategy}")
    
    # Count trainable parameters
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    
    # Save strategy information in model for proper restoration
    model.freeze_strategy = freeze_strategy
    if freeze_strategy == "lora":
        model.lora_rank = lora_rank
        model.lora_alpha = lora_alpha
    
    logger.info(f"üìä Parameters:")
    logger.info(f"   Total: {total_params:,}")
    logger.info(f"   Trainable: {trainable_params:,}")
    logger.info(f"   Trainable ratio: {trainable_params/total_params*100:.2f}%")


def create_training_plots(training_log: List[Dict], save_dir: str):
    """Create training plots (loss, ROC AUC and learning rate)"""
    if len(training_log) == 0:
        return
    
    # Extract data for plots
    steps = []
    train_losses = []
    test_losses = []
    train_roc_aucs = []
    test_roc_aucs = []
    learning_rates = []
    
    for entry in training_log:
        if 'step' in entry:
            steps.append(entry['step'])
            train_losses.append(entry.get('train_loss', None))
            test_losses.append(entry.get('test_loss', None))
            train_roc_aucs.append(entry.get('train_roc_auc', None))
            test_roc_aucs.append(entry.get('test_roc_auc', None))
            learning_rates.append(entry.get('lr', None))
    
    if len(steps) == 0:
        return
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ (3 –≥—Ä–∞—Ñ–∏–∫–∞ –≤–º–µ—Å—Ç–æ 2)
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))
    
    # –ì—Ä–∞—Ñ–∏–∫ Loss
    ax1.set_title('Training and Test Loss')
    if any(l is not None for l in train_losses):
        valid_steps = [s for s, l in zip(steps, train_losses) if l is not None]
        valid_losses = [l for l in train_losses if l is not None]
        if valid_steps:
            ax1.plot(valid_steps, valid_losses, 'b-', label='Train Loss', linewidth=2)
    
    if any(l is not None for l in test_losses):
        valid_steps = [s for s, l in zip(steps, test_losses) if l is not None]
        valid_losses = [l for l in test_losses if l is not None]
        if valid_steps:
            ax1.plot(valid_steps, valid_losses, 'r-', label='Test Loss', linewidth=2)
    
    ax1.set_xlabel('Training Steps')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ ROC AUC
    ax2.set_title('Training and Test ROC AUC')
    if any(auc is not None for auc in train_roc_aucs):
        valid_steps = [s for s, auc in zip(steps, train_roc_aucs) if auc is not None]
        valid_aucs = [auc for auc in train_roc_aucs if auc is not None]
        if valid_steps:
            ax2.plot(valid_steps, valid_aucs, 'b-', label='Train ROC AUC', linewidth=2)
    
    if any(auc is not None for auc in test_roc_aucs):
        valid_steps = [s for s, auc in zip(steps, test_roc_aucs) if auc is not None]
        valid_aucs = [auc for auc in test_roc_aucs if auc is not None]
        if valid_steps:
            ax2.plot(valid_steps, valid_aucs, 'r-', label='Test ROC AUC', linewidth=2)
    
    ax2.set_xlabel('Training Steps')
    ax2.set_ylabel('ROC AUC')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 1)
    
    # –ì—Ä–∞—Ñ–∏–∫ Learning Rate
    ax3.set_title('Learning Rate Schedule')
    if any(lr is not None for lr in learning_rates):
        valid_steps = [s for s, lr in zip(steps, learning_rates) if lr is not None]
        valid_lrs = [lr for lr in learning_rates if lr is not None]
        if valid_steps:
            ax3.plot(valid_steps, valid_lrs, 'g-', label='Learning Rate', linewidth=2)
    
    ax3.set_xlabel('Training Steps')
    ax3.set_ylabel('Learning Rate')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_yscale('log')  # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞ –¥–ª—è LR
    
    plt.tight_layout()
    plot_path = os.path.join(save_dir, 'training_progress.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    return plot_path


def evaluate_train_roc_auc(model: Qwen3CrossAttentionMetaModel, train_loader: DataLoader, device: str, max_batches: int = 10) -> float:
    """–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ ROC AUC –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_idx, (texts_1, texts_2, gt_matrix, dataset_name) in enumerate(train_loader):
            if batch_idx >= max_batches:
                break
                
            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DataLoader (batch_size=1)
            texts_1 = [item[0] for item in texts_1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            texts_2 = [item[0] for item in texts_2]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            gt_matrix = gt_matrix.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å batch: [1, 32, 32] -> [32, 32]
            
            pred_matrix = model(texts_1, texts_2)
            
            all_predictions.extend(pred_matrix.flatten().cpu().numpy())
            all_targets.extend(gt_matrix.flatten().cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # ROC AUC
    if len(np.unique(all_targets)) > 1 and len(all_predictions) > 0:
        return roc_auc_score(all_targets, all_predictions)
    else:
        return 0.0


def weighted_bce_loss(pred_matrix: torch.Tensor, gt_matrix: torch.Tensor) -> torch.Tensor:
    """–í–∑–≤–µ—à–µ–Ω–Ω—ã–π Binary Cross Entropy Loss"""
    ones_mask = (gt_matrix == 1)
    zeros_mask = (gt_matrix == 0)
    
    ones_count = ones_mask.sum().item()
    zeros_count = zeros_mask.sum().item()
    
    if ones_count == 0:
        return F.binary_cross_entropy(pred_matrix, gt_matrix)
    
    loss_ones = 0.0
    if ones_mask.sum() > 0:
        loss_ones = F.binary_cross_entropy(pred_matrix[ones_mask], gt_matrix[ones_mask])
    
    loss_zeros = 0.0
    if zeros_mask.sum() > 0:
        loss_zeros = F.binary_cross_entropy(pred_matrix[zeros_mask], gt_matrix[zeros_mask])
    
    total_loss = loss_ones / ones_count + loss_zeros / zeros_count
    return total_loss


def evaluate_meta_model(model: Qwen3CrossAttentionMetaModel, dataloader: DataLoader, device: str) -> Dict[str, float]:
    """–û—Ü–µ–Ω–∫–∞ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for texts_1, texts_2, gt_matrix, dataset_name in dataloader:
            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DataLoader (batch_size=1)
            texts_1 = [item[0] for item in texts_1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            texts_2 = [item[0] for item in texts_2]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            gt_matrix = gt_matrix.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å batch: [1, 32, 32] -> [32, 32]
            
            pred_matrix = model(texts_1, texts_2)
            
            all_predictions.extend(pred_matrix.flatten().cpu().numpy())
            all_targets.extend(gt_matrix.flatten().cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    metrics = {}
    
    # ROC AUC
    if len(np.unique(all_targets)) > 1:
        metrics['roc_auc'] = roc_auc_score(all_targets, all_predictions)
    else:
        metrics['roc_auc'] = 0.0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
    for threshold in [0.05, 0.15, 0.25, 0.5]:
        pred_binary = (all_predictions > threshold).astype(int)
        
        metrics[f'acc_{threshold}'] = accuracy_score(all_targets, pred_binary)
        metrics[f'f1_{threshold}'] = f1_score(all_targets, pred_binary, zero_division=0)
        metrics[f'precision_{threshold}'] = precision_score(all_targets, pred_binary, zero_division=0)
        metrics[f'recall_{threshold}'] = recall_score(all_targets, pred_binary, zero_division=0)
    
    return metrics


def analyze_thresholds(model: Qwen3CrossAttentionMetaModel, dataloader: DataLoader, device: str, save_dir: str = None) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏"""
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for texts_1, texts_2, gt_matrix, dataset_name in dataloader:
            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DataLoader (batch_size=1)
            texts_1 = [item[0] for item in texts_1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            texts_2 = [item[0] for item in texts_2]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            gt_matrix = gt_matrix.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å batch: [1, 32, 32] -> [32, 32]
            
            pred_matrix = model(texts_1, texts_2)
            
            all_predictions.extend(pred_matrix.flatten().cpu().numpy())
            all_targets.extend(gt_matrix.flatten().cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏ –æ—Ç 0.01 –¥–æ 0.95
    thresholds = np.arange(0.01, 0.95, 0.01)
    
    results = {
        'thresholds': thresholds.tolist(),
        'accuracy': [],
        'precision': [],
        'recall': [],
        'f1': []
    }
    
    for threshold in thresholds:
        pred_binary = (all_predictions > threshold).astype(int)
        
        acc = accuracy_score(all_targets, pred_binary)
        prec = precision_score(all_targets, pred_binary, zero_division=0)
        rec = recall_score(all_targets, pred_binary, zero_division=0)
        f1 = f1_score(all_targets, pred_binary, zero_division=0)
        
        results['accuracy'].append(acc)
        results['precision'].append(prec)
        results['recall'].append(rec)
        results['f1'].append(f1)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏
    best_thresholds = {
        'accuracy': thresholds[np.argmax(results['accuracy'])],
        'precision': thresholds[np.argmax(results['precision'])],
        'recall': thresholds[np.argmax(results['recall'])],
        'f1': thresholds[np.argmax(results['f1'])]
    }
    
    best_values = {
        'accuracy': np.max(results['accuracy']),
        'precision': np.max(results['precision']),
        'recall': np.max(results['recall']),
        'f1': np.max(results['f1'])
    }
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
    if save_dir:
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.plot(thresholds, results['accuracy'], 'b-', linewidth=2)
        plt.axvline(best_thresholds['accuracy'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Accuracy (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["accuracy"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["accuracy"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Accuracy')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 2)
        plt.plot(thresholds, results['precision'], 'g-', linewidth=2)
        plt.axvline(best_thresholds['precision'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Precision (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["precision"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["precision"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Precision')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 3)
        plt.plot(thresholds, results['recall'], 'orange', linewidth=2)
        plt.axvline(best_thresholds['recall'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Recall (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["recall"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["recall"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Recall')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 4)
        plt.plot(thresholds, results['f1'], 'purple', linewidth=2)
        plt.axvline(best_thresholds['f1'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'F1-Score (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["f1"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["f1"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('F1-Score')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plot_path = os.path.join(save_dir, 'threshold_analysis.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")
    
    analysis = {
        'threshold_analysis': results,
        'best_thresholds': best_thresholds,
        'best_values': best_values
    }
    
    return analysis


def train_meta_model(
    model: Qwen3CrossAttentionMetaModel,
    train_dataset: MetaModelDataset,
    test_dataset: MetaModelDataset,
    num_epochs: int = 10,
    learning_rate: float = 1e-4,
    device: str = "auto",
    save_dir: str = "./checkpoints",
    eval_every_steps: int = 100,
    save_metrics_every_steps: int = 50,
    batch_size: int = 1,
    num_workers: int = 0,
    max_steps: int = None,
    wandb_config: dict = None
):
    """–û–±—É—á–µ–Ω–∏–µ Meta-Model"""
    
    logger = setup_logging(os.path.join(save_dir, "logs"))
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è wandb
    use_wandb = wandb_config is not None and WANDB_AVAILABLE
    if use_wandb:
        wandb.init(
            project=wandb_config.get('project', 'llms4ol-meta-model'),
            name=wandb_config.get('name'),
            config=wandb_config.get('config', {}),
            tags=wandb_config.get('tags', []),
            notes=wandb_config.get('notes', ''),
            dir=save_dir
        )
        logger.info(f"üîó Wandb –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {wandb.run.name}")
    elif wandb_config is not None and not WANDB_AVAILABLE:
        logger.warning("‚ö†Ô∏è Wandb –∑–∞–ø—Ä–æ—à–µ–Ω, –Ω–æ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    model.train()
    
    # –°–æ–∑–¥–∞–µ–º DataLoaders
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True if device == "cuda" else False
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True if device == "cuda" else False
    )
    
    # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.AdamW(trainable_params, lr=learning_rate, weight_decay=0.01)
    
    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å warmup
    total_steps = len(train_loader) * num_epochs
    warmup_steps = int(total_steps * 0.1)  # 10% –æ—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤
    
    try:
        from transformers import get_cosine_schedule_with_warmup
        scheduler = get_cosine_schedule_with_warmup(
            optimizer,
            num_warmup_steps=warmup_steps,
            num_training_steps=total_steps
        )
        logger.info(f"üìà –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å warmup: {warmup_steps} —à–∞–≥–æ–≤ warmup –∏–∑ {total_steps} –æ–±—â–∏—Ö")
    except ImportError:
        # Fallback –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É scheduler –µ—Å–ª–∏ transformers –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)
        logger.info("‚ö†Ô∏è transformers –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π CosineAnnealingLR")
        warmup_steps = 0
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    results_dir = save_dir
    metrics_dir = os.path.join(save_dir, "metrics")
    os.makedirs(results_dir, exist_ok=True)
    os.makedirs(metrics_dir, exist_ok=True)
    
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è Meta-Model:")
    logger.info(f"   –≠–ø–æ—Ö–∏: {num_epochs}")
    logger.info(f"   –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: {len(train_loader)}")
    logger.info(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {total_steps}")
    logger.info(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    logger.info(f"   Learning rate: {learning_rate}")
    logger.info(f"   –û–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {len(trainable_params):,}")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    training_log = []
    step_counter = 0
    best_roc_auc = 0.0
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        model.train()
        epoch_loss = 0.0
        
        for batch_idx, (texts_1, texts_2, gt_matrix, dataset_name) in enumerate(train_loader):
            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DataLoader (batch_size=1)
            # DataLoader –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç: —Å–ø–∏—Å–æ–∫ –∏–∑ 32 —Å–ø–∏—Å–∫–æ–≤, –∫–∞–∂–¥—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç 1 —Å—Ç—Ä–æ–∫—É
            # –ù—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å–ø–∏—Å–∫–æ–≤
            texts_1 = [item[0] for item in texts_1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            texts_2 = [item[0] for item in texts_2]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
            gt_matrix = gt_matrix.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å batch: [1, 32, 32] -> [32, 32]
            
            # Forward pass
            pred_matrix = model(texts_1, texts_2)
            
            # Loss
            loss = weighted_bce_loss(pred_matrix, gt_matrix)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            epoch_loss += loss.item()
            step_counter += 1
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            basic_log_entry = {
                'step': step_counter,
                'epoch': epoch,
                'batch': batch_idx,
                'train_loss': loss.item(),
                'lr': scheduler.get_last_lr()[0],
                'dataset': dataset_name,
                'timestamp': datetime.now().isoformat()
            }
            training_log.append(basic_log_entry)
            
            # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ wandb
            if use_wandb:
                wandb.log({
                    'train/loss': loss.item(),
                    'train/learning_rate': scheduler.get_last_lr()[0],
                    'train/epoch': epoch,
                    'train/step': step_counter
                }, step=step_counter)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ max_steps
            if max_steps is not None and step_counter >= max_steps:
                logger.info(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {max_steps}")
                break
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            if step_counter % save_metrics_every_steps == 0:
                log_message = (f"–®–∞–≥ {step_counter:5d} | –≠–ø–æ—Ö–∞ {epoch+1:2d}/{num_epochs} | "
                              f"Train Loss: {loss.item():.4f} | "
                              f"LR: {scheduler.get_last_lr()[0]:.6f}")
                logger.info(log_message)
            
            # –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            if step_counter % eval_every_steps == 0:
                logger.info(f"\nüìä –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —à–∞–≥–µ {step_counter}...")
                
                # –ë—ã—Å—Ç—Ä—ã–π test_loss
                model.eval()
                with torch.no_grad():
                    test_texts_1, test_texts_2, test_gt_matrix, test_dataset_name = next(iter(test_loader))
                    # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ DataLoader (batch_size=1)
                    test_texts_1 = [item[0] for item in test_texts_1]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
                    test_texts_2 = [item[0] for item in test_texts_2]  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Å–ø–∏—Å–∫–æ–≤
                    test_gt_matrix = test_gt_matrix.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å batch: [1, 32, 32] -> [32, 32]
                    
                    test_pred_matrix = model(test_texts_1, test_texts_2)
                    test_loss_for_curves = weighted_bce_loss(test_pred_matrix, test_gt_matrix)
                
                # –í—ã—á–∏—Å–ª—è–µ–º train ROC AUC –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–µ
                train_roc_auc = evaluate_train_roc_auc(model, train_loader, device, max_batches=10)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º training_log —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
                training_log[-1]['test_loss'] = test_loss_for_curves.item()
                training_log[-1]['train_roc_auc'] = train_roc_auc
                
                # –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ –ù–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•
                logger.info(f"üîç –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
                metrics = evaluate_meta_model(model, test_loader, device)
                
                # –î–æ–±–∞–≤–ª—è–µ–º test ROC AUC –≤ –ª–æ–≥
                training_log[-1]['test_roc_auc'] = metrics['roc_auc']
                
                # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ wandb
                if use_wandb:
                    wandb_metrics = {
                        'test/loss': test_loss_for_curves.item(),
                        'test/roc_auc': metrics['roc_auc'],
                        'train/roc_auc': train_roc_auc,
                    }
                    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
                    for threshold in [0.05, 0.15, 0.25, 0.5]:
                        wandb_metrics[f'test/acc_{threshold}'] = metrics[f'acc_{threshold}']
                        wandb_metrics[f'test/f1_{threshold}'] = metrics[f'f1_{threshold}']
                        wandb_metrics[f'test/precision_{threshold}'] = metrics[f'precision_{threshold}']
                        wandb_metrics[f'test/recall_{threshold}'] = metrics[f'recall_{threshold}']
                    
                    wandb.log(wandb_metrics, step=step_counter)
                
                logger.info(f"üéØ –ú–µ—Ç—Ä–∏–∫–∏ (–¢–ï–°–¢):")
                logger.info(f"   Test ROC AUC: {metrics['roc_auc']:.4f}")
                logger.info(f"   Train ROC AUC: {train_roc_auc:.4f}")
                for threshold in [0.05, 0.15, 0.25, 0.5]:
                    threshold_msg = (f"   –ü–æ—Ä–æ–≥ {threshold}: Acc={metrics[f'acc_{threshold}']:.3f}, "
                                   f"F1={metrics[f'f1_{threshold}']:.3f}")
                    logger.info(threshold_msg)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                metrics['step'] = step_counter
                metrics['epoch'] = epoch
                metrics['train_roc_auc'] = train_roc_auc
                save_metrics(metrics, f"{metrics_dir}/metrics_step_{step_counter}.json")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (—É–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é)
                current_roc_auc = metrics['roc_auc']
                if current_roc_auc > best_roc_auc:
                    # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                    old_best_dirs = [d for d in os.listdir(results_dir) if d.startswith("best_model_step_")]
                    for old_dir in old_best_dirs:
                        old_path = os.path.join(results_dir, old_dir)
                        if os.path.isdir(old_path):
                            import shutil
                            shutil.rmtree(old_path)
                            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –º–æ–¥–µ–ª—å: {old_dir}")
                    
                    best_roc_auc = current_roc_auc
                    best_model_dir = os.path.join(results_dir, f"best_model_step_{step_counter}_auc_{current_roc_auc:.4f}")
                    model.save_pretrained(best_model_dir)
                    
                    # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                    threshold_analysis = analyze_thresholds(model, test_loader, device, best_model_dir)
                    with open(os.path.join(best_model_dir, 'threshold_analysis.json'), 'w') as f:
                        json.dump(threshold_analysis, f, indent=2)
                    
                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π F1 threshold
                    model.f1_threshold = float(threshold_analysis['best_thresholds']['f1'])
                    
                    logger.info(f"üíæ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (Test ROC AUC: {current_roc_auc:.4f})")
                    logger.info(f"üéØ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π F1 threshold: {model.f1_threshold:.4f}")
                
                # –°–æ–∑–¥–∞–µ–º –æ–±–Ω–æ–≤–ª—è–µ–º—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
                plot_path = create_training_plots(training_log, results_dir)
                if plot_path:
                    logger.info(f"üìà –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω—ã: training_progress.png")
                
                model.train()
                logger.info("")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ max_steps
        if max_steps is not None and step_counter >= max_steps:
            break
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–æ—Ö–∏
        avg_epoch_loss = epoch_loss / len(train_loader)
        elapsed_time = time.time() - start_time
        
        logger.info(f"\nüìà –≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs} –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π loss: {avg_epoch_loss:.4f}")
        logger.info(f"   –í—Ä–µ–º—è: {elapsed_time/60:.1f} –º–∏–Ω")
        logger.info(f"   –õ—É—á—à–∏–π ROC AUC: {best_roc_auc:.4f}")
        logger.info("-" * 60)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è
    with open(f"{metrics_dir}/training_log.json", 'w') as f:
        json.dump(training_log, f, indent=2)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    logger.info(f"\nüèÅ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    final_metrics = evaluate_meta_model(model, test_loader, device)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π train ROC AUC
    final_train_roc_auc = evaluate_train_roc_auc(model, train_loader, device, max_batches=20)
    final_metrics['train_roc_auc'] = final_train_roc_auc
    
    save_metrics(final_metrics, f"{metrics_dir}/final_metrics.json")
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤
    logger.info(f"\nüîç –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    threshold_analysis = analyze_thresholds(model, test_loader, device, results_dir)
    save_metrics(threshold_analysis, f"{metrics_dir}/threshold_analysis.json")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
    final_plot_path = create_training_plots(training_log, results_dir)
    
    logger.info(f"üìä –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ (–Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö):")
    for metric, threshold in threshold_analysis['best_thresholds'].items():
        value = threshold_analysis['best_values'][metric]
        logger.info(f"   {metric.capitalize()}: {threshold:.2f} (–∑–Ω–∞—á–µ–Ω–∏–µ: {value:.4f})")
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ wandb
    if use_wandb:
        final_wandb_metrics = {
            'final/test_roc_auc': final_metrics['roc_auc'],
            'final/train_roc_auc': final_train_roc_auc,
            'final/best_test_roc_auc': best_roc_auc,
            'final/training_time_minutes': (time.time() - start_time) / 60,
            'final/total_steps': step_counter
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏
        for metric, threshold in threshold_analysis['best_thresholds'].items():
            final_wandb_metrics[f'best_threshold/{metric}'] = threshold
            final_wandb_metrics[f'best_value/{metric}'] = threshold_analysis['best_values'][metric]
        
        wandb.log(final_wandb_metrics, step=step_counter)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –≤ wandb
        if final_plot_path and os.path.exists(final_plot_path):
            wandb.log({"charts/training_progress": wandb.Image(final_plot_path)})
        
        threshold_plot_path = os.path.join(results_dir, 'threshold_analysis.png')
        if os.path.exists(threshold_plot_path):
            wandb.log({"charts/threshold_analysis": wandb.Image(threshold_plot_path)})
        
        wandb.finish()
        logger.info(f"üîó Wandb run –∑–∞–≤–µ—Ä—à–µ–Ω: {wandb.run.url if wandb.run else 'N/A'}")
    
    logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ Meta-Model –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    logger.info(f"   –§–∏–Ω–∞–ª—å–Ω—ã–π Test ROC AUC: {final_metrics['roc_auc']:.4f}")
    logger.info(f"   –§–∏–Ω–∞–ª—å–Ω—ã–π Train ROC AUC: {final_train_roc_auc:.4f}")
    logger.info(f"   –õ—É—á—à–∏–π Test ROC AUC: {best_roc_auc:.4f}")
    logger.info(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {(time.time() - start_time)/60:.1f} –º–∏–Ω")
    if final_plot_path:
        logger.info(f"   üìà –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è: training_progress.png")
    
    return model, training_log, final_metrics, threshold_analysis


def save_metrics(metrics: Dict[str, Any], filepath: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ JSON —Ñ–∞–π–ª"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w') as f:
        json.dump(metrics, f, indent=2)


def create_experiment_name(args) -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    parts = [
        args.dataset_name,
        f"ep{args.epochs}",
        f"lr{args.lr:.0e}",
        f"bs{args.batch_size}",
        f"eval{args.eval_every}",
        f"seed{args.seed}",
        f"freeze_{args.freeze_strategy}"
    ]
    
    if args.qwen3_model != "Qwen/Qwen3-Embedding-0.6B":
        model_short = args.qwen3_model.split('/')[-1].lower().replace('-', '_')
        parts.append(model_short)
    
    if args.embedding_pooling != "last_token_norm":
        parts.append(f"pool_{args.embedding_pooling}")
    
    if args.max_steps:
        parts.append(f"max{args.max_steps}")
    
    if args.freeze_strategy == "lora":
        parts.append(f"r{args.lora_rank}_a{args.lora_alpha}")
    
    experiment_name = f"{timestamp}_{'_'.join(parts)}"
    return experiment_name


def show_usage_examples():
    """–ü–æ–∫–∞–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    examples = """
üöÄ –û–ë–£–ß–ï–ù–ò–ï META-MODEL - –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:

1. –ü–æ–ª–Ω–∞—è –∑–∞–º–æ—Ä–æ–∑–∫–∞ Qwen3 (–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ):
   python train_meta_model.py \\
       --terms_path data/doid_train_types.txt \\
       --relations_path data/doid_train_pairs.json \\
       --output_dir experiments/freeze_full \\
       --dataset_name DOID \\
       --freeze_strategy full \\
       --epochs 10 \\
       --lr 1e-4

2. –ó–∞–º–æ—Ä–æ–∑–∫–∞ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ—è (—Å—Ä–µ–¥–Ω—è—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è):
   python train_meta_model.py \\
       --terms_path data/doid_train_types.txt \\
       --relations_path data/doid_train_pairs.json \\
       --output_dir experiments/freeze_except_last \\
       --dataset_name DOID \\
       --freeze_strategy except_last \\
       --epochs 15 \\
       --lr 5e-5

3. LORA –∞–¥–∞–ø—Ç–µ—Ä (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è):
   python train_meta_model.py \\
       --terms_path data/doid_train_types.txt \\
       --relations_path data/doid_train_pairs.json \\
       --output_dir experiments/lora_training \\
       --dataset_name DOID \\
       --freeze_strategy lora \\
       --lora_rank 16 \\
       --lora_alpha 32 \\
       --epochs 20 \\
       --lr 1e-4

4. –ë–µ–∑ –∑–∞–º–æ—Ä–æ–∑–∫–∏ (–ø–æ–ª–Ω–æ–µ –¥–æ–æ–±—É—á–µ–Ω–∏–µ):
   python train_meta_model.py \\
       --terms_path data/doid_train_types.txt \\
       --relations_path data/doid_train_pairs.json \\
       --output_dir experiments/full_training \\
       --dataset_name DOID \\
       --freeze_strategy none \\
       --epochs 5 \\
       --lr 1e-5

5. –ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:
   python train_meta_model.py \\
       --terms_path data/small_test.txt \\
       --relations_path data/small_test.json \\
       --output_dir experiments/quick_test \\
       --dataset_name TEST \\
       --freeze_strategy full \\
       --epochs 2 \\
       --max_steps 50 \\
       --eval_every 10

6. –û–±—É—á–µ–Ω–∏–µ —Å wandb –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º:
   python train_meta_model.py \\
       --terms_path data/doid_train_types.txt \\
       --relations_path data/doid_train_pairs.json \\
       --output_dir experiments/wandb_training \\
       --dataset_name DOID \\
       --freeze_strategy lora \\
       --epochs 15 \\
       --wandb \\
       --wandb_project "doid-meta-model" \\
       --wandb_name "lora_r16_a32_experiment" \\
       --wandb_tags "lora" "doid" "meta-model" \\
       --wandb_notes "–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å LORA –∞–¥–∞–ø—Ç–µ—Ä–æ–º"

üìù –ö–õ–Æ–ß–ï–í–´–ï –ü–ê–†–ê–ú–ï–¢–†–´:
   --freeze_strategy: "full", "except_last", "lora", "none"
   --lora_rank: Rank –¥–ª—è LORA –∞–¥–∞–ø—Ç–µ—Ä–∞ (4-64, –æ–±—ã—á–Ω–æ 8-16)
   --lora_alpha: Alpha –¥–ª—è LORA (–æ–±—ã—á–Ω–æ 16-32)
   --embedding_pooling: "mean", "last_token", "last_token_norm"
   
   WANDB –ü–ê–†–ê–ú–ï–¢–†–´:
   --wandb: –í–∫–ª—é—á–∏—Ç—å wandb –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
   --wandb_project: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤ wandb
   --wandb_name: –ù–∞–∑–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–∞–≤—Ç–æ –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ)
   --wandb_tags: –¢–µ–≥–∏ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
   --wandb_notes: –û–ø–∏—Å–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
   ‚Ä¢ full: –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π, –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–º–µ–Ω–æ–≤
   ‚Ä¢ except_last: –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
   ‚Ä¢ lora: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–æ–¥ –Ω–æ–≤—ã–µ –¥–æ–º–µ–Ω—ã
   ‚Ä¢ none: –°–∞–º–æ–µ –º–µ–¥–ª–µ–Ω–Ω–æ–µ, –Ω–æ –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
   ‚Ä¢ –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å except_last –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –∑–∞–¥–∞—á
   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ wandb –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    """
    print(examples)


if __name__ == "__main__":
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –µ—Å–ª–∏ –∑–∞–ø—É—Å—Ç–∏–ª–∏ –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    if len(sys.argv) == 1:
        print("üöÄ –û–±—É—á–µ–Ω–∏–µ Meta-Model —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –æ–ø—Ü–∏—è–º–∏ –∑–∞–º–æ—Ä–æ–∑–∫–∏")
        print("=" * 70)
        show_usage_examples()
        print("\nüìñ –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–π —Å–ø—Ä–∞–≤–∫–∏:")
        print("   python train_meta_model.py --help")
        sys.exit(0)
    
    parser = argparse.ArgumentParser(
        description="Meta-Model Training with Advanced Freezing Options",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="üî• –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è Meta-Model —Å txt —Ñ–∞–π–ª–∞–º–∏!"
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--terms_path", type=str, required=True, help="Path to terms TXT file")
    parser.add_argument("--relations_path", type=str, required=True, help="Path to relations JSON file")
    parser.add_argument("--output_dir", type=str, required=True, help="Output directory")
    parser.add_argument("--dataset_name", type=str, required=True, help="Dataset name")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument("--epochs", type=int, default=10, help="Number of epochs")
    parser.add_argument("--batch_size", type=int, default=32, help="Batch size")
    parser.add_argument("--eval_every", type=int, default=100, help="Evaluate every N steps")
    parser.add_argument("--save_every", type=int, default=50, help="Save every N steps")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate")
    parser.add_argument("--test_size", type=float, default=0.2, help="Test split size")
    parser.add_argument("--max_steps", type=int, default=None, help="Maximum training steps")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    parser.add_argument("--qwen3_model", type=str, default="Qwen/Qwen3-Embedding-0.6B", help="Qwen3 model name")
    parser.add_argument("--embedding_pooling", type=str, default="last_token_norm", 
                       choices=["mean", "last_token", "last_token_norm"], help="Embedding pooling method")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–º–æ—Ä–æ–∑–∫–∏ (–ù–û–í–û–ï!)
    parser.add_argument("--freeze_strategy", type=str, default="full", 
                       choices=["full", "except_last", "lora", "none"],
                       help="Freezing strategy for Qwen3 weights")
    parser.add_argument("--lora_rank", type=int, default=8, help="LORA rank (for lora strategy)")
    parser.add_argument("--lora_alpha", type=int, default=16, help="LORA alpha (for lora strategy)")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞—Ç–∞—Å–µ—Ç–∞
    parser.add_argument("--dataset_strategy", type=str, default="single", 
                       choices=["single", "weighted"], help="Dataset selection strategy")
    parser.add_argument("--sampling_strategy", type=str, default="balanced", 
                       choices=["random", "balanced"], help="Sampling strategy")
    parser.add_argument("--positive_ratio", type=float, default=1.0, help="Positive pairs ratio")
    
    # –ü—Ä–æ—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--log_level", type=str, default="INFO", 
                       choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="Logging level")
    
    # Wandb –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument("--wandb", action="store_true", help="Enable wandb logging")
    parser.add_argument("--wandb_project", type=str, default="llms4ol-meta-model", help="Wandb project name")
    parser.add_argument("--wandb_name", type=str, default=None, help="Wandb run name (auto if None)")
    parser.add_argument("--wandb_tags", type=str, nargs="*", default=[], help="Wandb tags")
    parser.add_argument("--wandb_notes", type=str, default="", help="Wandb run notes")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    experiment_name = create_experiment_name(args)
    experiment_dir = os.path.join(args.output_dir, experiment_name)
    os.makedirs(experiment_dir, exist_ok=True)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger = setup_logging(experiment_dir, args.log_level)
    
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_name}")
    logger.info(f"üìÅ –ü–∞–ø–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_dir}")
    logger.info(f"üé≤ Seed: {args.seed}")
    logger.info(f"üßä –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∑–∞–º–æ—Ä–æ–∑–∫–∏: {args.freeze_strategy}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    logger.info(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    logger.info(f"   Terms: {args.terms_path}")
    logger.info(f"   Relations: {args.relations_path}")
    
    train_dataset = MetaModelDataset(
        terms_path=args.terms_path,
        relations_path=args.relations_path,
        batch_size_1=args.batch_size,
        batch_size_2=args.batch_size,
        dataset_strategy=args.dataset_strategy,
        sampling_strategy=args.sampling_strategy,
        positive_ratio=args.positive_ratio,
        mode="train",
        test_part=args.test_size,
        random_state=args.seed
    )
    
    test_dataset = MetaModelDataset(
        terms_path=args.terms_path,
        relations_path=args.relations_path,
        batch_size_1=args.batch_size,
        batch_size_2=args.batch_size,
        dataset_strategy=args.dataset_strategy,
        sampling_strategy=args.sampling_strategy,
        positive_ratio=args.positive_ratio,
        mode="test",
        test_part=args.test_size,
        random_state=args.seed
    )
    
    logger.info(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã: Train={len(train_dataset)}, Test={len(test_dataset)}")
    
    # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å
    logger.info(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ Meta-Model: {args.qwen3_model}")
    
    model = create_meta_model_from_scratch(
        qwen3_model_name=args.qwen3_model,
        embedding_pooling=args.embedding_pooling,
        init_from_qwen3=True,  # –í—Å–µ–≥–¥–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑ Qwen3
        device="auto"
    )
    
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {model}")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∑–∞–º–æ—Ä–æ–∑–∫–∏
    apply_freeze_strategy(model, args.freeze_strategy, args.lora_rank, args.lora_alpha)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ wandb
    wandb_config = None
    if args.wandb and WANDB_AVAILABLE:
        wandb_config = {
            'project': args.wandb_project,
            'name': args.wandb_name or experiment_name,
            'tags': args.wandb_tags + [args.dataset_name, args.freeze_strategy],
            'notes': args.wandb_notes,
            'config': {
                'experiment_name': experiment_name,
                'dataset_name': args.dataset_name,
                'epochs': args.epochs,
                'learning_rate': args.lr,
                'batch_size': args.batch_size,
                'freeze_strategy': args.freeze_strategy,
                'lora_rank': args.lora_rank if args.freeze_strategy == "lora" else None,
                'lora_alpha': args.lora_alpha if args.freeze_strategy == "lora" else None,
                'qwen3_model': args.qwen3_model,
                'embedding_pooling': args.embedding_pooling,
                'test_size': args.test_size,
                'max_steps': args.max_steps,
                'seed': args.seed,
                'eval_every_steps': args.eval_every,
                'dataset_strategy': args.dataset_strategy,
                'sampling_strategy': args.sampling_strategy,
                'positive_ratio': args.positive_ratio
            }
        }
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    logger.info(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    if wandb_config:
        logger.info(f"üîó Wandb –ø—Ä–æ–µ–∫—Ç: {wandb_config['project']}")
        logger.info(f"üîó Wandb run: {wandb_config['name']}")
    
    trained_model, training_log, final_metrics, threshold_analysis = train_meta_model(
        model=model,
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        num_epochs=args.epochs,
        learning_rate=args.lr,
        save_dir=experiment_dir,
        eval_every_steps=args.eval_every,
        save_metrics_every_steps=args.save_every,
        batch_size=1,  # DataLoader batch size
        num_workers=0,
        max_steps=args.max_steps,
        wandb_config=wandb_config
    )
    
    logger.info(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {experiment_dir}")
    logger.info(f"   üìä –ì—Ä–∞—Ñ–∏–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤: threshold_analysis.png")
    logger.info(f"   üìÇ –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: metrics/")
    logger.info(f"   üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: best_model_step_*/") 