"""
Cross-Attention model initialization and training system
Includes initialization from Qwen3, weighted loss, metrics and saving best models.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from transformers import AutoModel, AutoConfig
import numpy as np
import os
import json
from typing import Dict, List, Tuple, Optional, Any
from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score
import time
from datetime import datetime
import logging
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # –î–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è –±–µ–∑ GUI

from cross_attention_model import CrossAttentionModel
from dataset import CrossAttentionDataset, create_train_test_datasets


def create_experiment_name(args) -> str:
    """
    –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∏ –≤—Ä–µ–º–µ–Ω–∏
    
    Args:
        args: –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        
    Returns:
        experiment_name: —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏–º–µ–Ω–∏
    parts = [
        args.dataset_name,
        f"ep{args.epochs}",
        f"lr{args.lr:.0e}",
        f"bs{args.batch_size}",
        f"eval{args.eval_every}",
        f"seed{getattr(args, 'seed', 42)}"
    ]
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if args.dataset_strategy != "single":
        parts.append(f"ds_{args.dataset_strategy}")
    
    if args.sampling_strategy != "balanced":
        parts.append(f"samp_{args.sampling_strategy}")
    
    if args.positive_ratio != 1.0:
        parts.append(f"pos{args.positive_ratio}")
        
    if args.use_qwen3:
        parts.append("qwen3")
    
    if args.max_steps:
        parts.append(f"max{args.max_steps}")
    
    experiment_name = f"{timestamp}_{'_'.join(parts)}"
    
    return experiment_name


def create_best_results_summary(
    threshold_analysis: Dict[str, Any],
    final_metrics: Dict[str, float],
    training_log: List[Dict],
    args,
    save_path: str
):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ JSON —Å –ª—É—á—à–∏–º–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Args:
        threshold_analysis: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤
        final_metrics: —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        training_log: –ª–æ–≥ –æ–±—É—á–µ–Ω–∏—è
        args: –∞—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        save_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    
    # –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è
    best_thresholds = threshold_analysis['best_thresholds']
    best_values = threshold_analysis['best_values']
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏
    training_info = {
        'total_steps': len(training_log),
        'final_train_loss': training_log[-1]['train_loss'] if training_log else None,
        'final_test_loss': training_log[-1].get('test_loss', None) if training_log else None,
        'best_train_loss': min(entry['train_loss'] for entry in training_log) if training_log else None,
        'best_test_loss': min(entry.get('test_loss', float('inf')) for entry in training_log 
                             if 'test_loss' in entry) if training_log else None,
    }
    
    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É
    summary = {
        'experiment_info': {
            'dataset': args.dataset_name,
            'timestamp': datetime.now().isoformat(),
            'experiment_args': {
                'epochs': args.epochs,
                'learning_rate': args.lr,
                'batch_size': args.batch_size,
                'eval_every': args.eval_every,
                'seed': getattr(args, 'seed', 42),
                'dataset_strategy': args.dataset_strategy,
                'sampling_strategy': args.sampling_strategy,
                'positive_ratio': args.positive_ratio,
                'use_qwen3': args.use_qwen3,
                'max_steps': args.max_steps,
                'test_size': args.test_size
            }
        },
        'best_results': {
            'roc_auc': final_metrics.get('roc_auc', 0.0),
            'best_thresholds': {
                'accuracy': {
                    'threshold': float(best_thresholds['accuracy']),
                    'value': float(best_values['accuracy'])
                },
                'precision': {
                    'threshold': float(best_thresholds['precision']),
                    'value': float(best_values['precision'])
                },
                'recall': {
                    'threshold': float(best_thresholds['recall']),
                    'value': float(best_values['recall'])
                },
                'f1_score': {
                    'threshold': float(best_thresholds['f1']),
                    'value': float(best_values['f1'])
                }
            }
        },
        'training_summary': training_info,
        'files_generated': {
            'training_curves': 'training_curves.png',
            'metrics_curves': 'metrics_curves.png',
            'threshold_analysis': 'threshold_analysis.png',
            'detailed_metrics': 'metrics/',
            'training_log': 'metrics/training_log.json',
            'threshold_analysis_detailed': 'metrics/threshold_analysis.json',
            'best_models': 'best_models/',
            'best_model_threshold_analysis': 'best_models/best_model_threshold_analysis.png',
            'best_model_threshold_analysis_detailed': 'best_models/best_model_threshold_analysis.json',
            'best_model_evaluation_summary': 'best_models/best_model_evaluation_summary.json'
        }
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É
    with open(save_path, 'w') as f:
        json.dump(summary, f, indent=2)
    
    print(f"üìã –°–≤–æ–¥–∫–∞ –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
    print(f"üéØ –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏:")
    for metric, info in summary['best_results']['best_thresholds'].items():
        print(f"   {metric.capitalize()}: {info['threshold']:.2f} (–∑–Ω–∞—á–µ–Ω–∏–µ: {info['value']:.4f})")


def setup_logging(log_dir: str, log_level: str = "INFO") -> logging.Logger:
    """
    –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª –∏ –∫–æ–Ω—Å–æ–ª—å
    
    Args:
        log_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤
        log_level: —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        
    Returns:
        logger: –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ª–æ–≥–≥–µ—Ä
    """
    os.makedirs(log_dir, exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä
    logger = logging.getLogger("cross_attention_training")
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
    logger.handlers.clear()
    
    # –§–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è –ª–æ–≥–æ–≤
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # Handler –¥–ª—è —Ñ–∞–π–ª–∞
    log_file = os.path.join(log_dir, f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(formatter)
    
    # Handler –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(formatter)
    
    # –î–æ–±–∞–≤–ª—è–µ–º handlers –∫ –ª–æ–≥–≥–µ—Ä—É
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    logger.info(f"–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –§–∞–π–ª –ª–æ–≥–∞: {log_file}")
    
    return logger


def initialize_from_qwen3(
    model_name: str, 
    layer_idx: int = -1,
    device: str = "auto"
) -> CrossAttentionModel:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CrossAttentionModel –≤–µ—Å–∞–º–∏ –∏–∑ Qwen3
    
    Args:
        model_name: –∏–º—è –º–æ–¥–µ–ª–∏ Qwen3 (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Qwen/Qwen3-4B")
        layer_idx: –∏–Ω–¥–µ–∫—Å —Å–ª–æ—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (-1 –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
        
    Returns:
        model: –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è CrossAttentionModel
    """
    print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Qwen3 –º–æ–¥–µ–ª–∏: {model_name}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ Qwen3 –º–æ–¥–µ–ª–∏
    try:
        qwen3_model = AutoModel.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map=device if device == "cuda" else None,
            trust_remote_code=True
        )
        config = qwen3_model.config
        print(f"‚úÖ Qwen3 –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Qwen3: {e}")
        raise
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª–æ–π –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    if layer_idx == -1:
        layer_idx = len(qwen3_model.layers) - 1
        
    if layer_idx >= len(qwen3_model.layers):
        raise ValueError(f"layer_idx {layer_idx} >= –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–µ–≤ {len(qwen3_model.layers)}")
    
    layer = qwen3_model.layers[layer_idx]
    attention = layer.self_attn
    
    print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–π {layer_idx} –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ CrossAttentionModel —Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    cross_model = CrossAttentionModel(config, layer_idx=layer_idx)
    
    # –ü–µ—Ä–µ–Ω–æ—Å –≤–µ—Å–æ–≤
    print(f"üìã –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤...")
    try:
        # Query projection
        cross_model.q_proj.weight.data = attention.q_proj.weight.data.clone().to(torch.float32)
        if cross_model.q_proj.bias is not None and attention.q_proj.bias is not None:
            cross_model.q_proj.bias.data = attention.q_proj.bias.data.clone().to(torch.float32)
        
        # Key projection
        cross_model.k_proj.weight.data = attention.k_proj.weight.data.clone().to(torch.float32)
        if cross_model.k_proj.bias is not None and attention.k_proj.bias is not None:
            cross_model.k_proj.bias.data = attention.k_proj.bias.data.clone().to(torch.float32)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        cross_model.q_norm.weight.data = attention.q_norm.weight.data.clone().to(torch.float32)
        cross_model.k_norm.weight.data = attention.k_norm.weight.data.clone().to(torch.float32)
        
        cross_model.initialized_from_qwen3 = True
        print(f"‚úÖ –í–µ—Å–∞ —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –∏–∑ —Å–ª–æ—è {layer_idx}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ—Å–æ–≤: {e}")
        raise
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –æ—Ç Qwen3
    del qwen3_model
    torch.cuda.empty_cache() if device == "cuda" else None
    
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    cross_model = cross_model.to(device)
    
    print(f"üöÄ CrossAttentionModel –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—É—á–µ–Ω–∏—é!")
    print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in cross_model.parameters() if p.requires_grad):,}")
    print(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    return cross_model


def weighted_bce_loss(pred_matrix: torch.Tensor, gt_matrix: torch.Tensor) -> torch.Tensor:
    """
    –í–∑–≤–µ—à–µ–Ω–Ω—ã–π Binary Cross Entropy Loss
    loss = loss[ones_places]/len(ones_places) + loss[zeros_places]/len(ones_places)
    
    Args:
        pred_matrix: (n, m) –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –≤–Ω–∏–º–∞–Ω–∏—è
        gt_matrix: (n, m) ground truth –º–∞—Ç—Ä–∏—Ü–∞ –æ—Ç–Ω–æ—à–µ–Ω–∏–π
        
    Returns:
        loss: –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –ª–æ—Å—Å
    """
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –µ–¥–∏–Ω–∏—Ü—ã –∏ –Ω—É–ª–∏
    ones_mask = (gt_matrix == 1)
    zeros_mask = (gt_matrix == 0)
    
    ones_count = ones_mask.sum().item()
    zeros_count = zeros_mask.sum().item()
    
    if ones_count == 0:
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π BCE
        logger = logging.getLogger("cross_attention_training")
        logger.warning("No positive examples found, using regular BCE")
        return F.binary_cross_entropy(pred_matrix, gt_matrix)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ª–æ—Å—Å–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –µ–¥–∏–Ω–∏—Ü –∏ –Ω—É–ª–µ–π
    loss_ones = 0.0
    if ones_mask.sum() > 0:
        loss_ones = F.binary_cross_entropy(pred_matrix[ones_mask], gt_matrix[ones_mask])
    
    loss_zeros = 0.0
    if zeros_mask.sum() > 0:
        loss_zeros = F.binary_cross_entropy(pred_matrix[zeros_mask], gt_matrix[zeros_mask])
    
    # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
    total_loss = loss_ones / ones_count + loss_zeros / zeros_count
    
    return total_loss


class BestModelSaver:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –ø–æ ROC AUC"""
    
    def __init__(self, save_dir: str, keep_top_k: int = 2, test_loader: DataLoader = None, device: str = "cuda"):
        self.save_dir = save_dir
        self.keep_top_k = keep_top_k
        self.best_scores = []  # [(roc_auc, step, model_path), ...]
        self.test_loader = test_loader
        self.device = device
        os.makedirs(save_dir, exist_ok=True)
        
    def save_if_best(self, model: CrossAttentionModel, roc_auc: float, step: int, 
                     metrics: Dict[str, float] = None):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –æ–Ω–∞ –≤ —Ç–æ–ø–µ –ø–æ ROC AUC"""
        
        model_filename = f"model_step_{step}_auc_{roc_auc:.4f}.pt"
        model_path = os.path.join(self.save_dir, model_filename)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å
        # –°–æ–∑–¥–∞–µ–º config –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏
        state_dict = model.state_dict()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –∏–∑ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –≤–µ—Å–æ–≤
        q_proj_weight = state_dict['q_proj.weight']
        k_proj_weight = state_dict['k_proj.weight']
        q_norm_weight = state_dict['q_norm.weight']
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –≤–µ—Å–æ–≤
        num_attention_heads_actual = q_proj_weight.shape[0] // q_norm_weight.shape[0]
        num_key_value_heads_actual = k_proj_weight.shape[0] // q_norm_weight.shape[0]
        head_dim_actual = q_norm_weight.shape[0]
        hidden_size_actual = q_proj_weight.shape[1]
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π config –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑–º–µ—Ä–æ–≤
        config_dict = {
            'hidden_size': hidden_size_actual,
            'num_attention_heads': num_attention_heads_actual,
            'num_key_value_heads': num_key_value_heads_actual,
            'head_dim': head_dim_actual,
            'rms_norm_eps': getattr(model.config, 'rms_norm_eps', 1e-6) if hasattr(model.config, 'rms_norm_eps') else model.config.get('rms_norm_eps', 1e-6),
            'attention_bias': getattr(model.config, 'attention_bias', False) if hasattr(model.config, 'attention_bias') else model.config.get('attention_bias', False)
        }
        
        checkpoint = {
            'model_state_dict': state_dict,
            'config': config_dict,
            'roc_auc': float(roc_auc),  # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —ç—Ç–æ Python float
            'step': int(step),          # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —ç—Ç–æ Python int
            'layer_idx': int(model.layer_idx),
            'initialized_from_qwen3': bool(model.initialized_from_qwen3),
            'metrics': {k: float(v) if isinstance(v, (int, float)) else v 
                       for k, v in (metrics or {}).items()},
            'timestamp': datetime.now().isoformat()
        }
        
        torch.save(checkpoint, model_path)
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ª—É—á—à–∏—Ö
        self.best_scores.append((roc_auc, step, model_path))
        self.best_scores.sort(reverse=True)  # –ü–æ —É–±—ã–≤–∞–Ω–∏—é ROC AUC
        
        # –£–¥–∞–ª–∏—Ç—å –ª–∏—à–Ω–∏–µ –º–æ–¥–µ–ª–∏
        while len(self.best_scores) > self.keep_top_k:
            _, _, old_path = self.best_scores.pop()
            if os.path.exists(old_path):
                os.remove(old_path)
                print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å: {os.path.basename(old_path)}")
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_filename} (ROC AUC: {roc_auc:.4f})")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if self.test_loader is not None:
            print(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏...")
            threshold_analysis = analyze_thresholds(
                model, 
                self.test_loader, 
                self.device,
                save_dir=self.save_dir  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫ –≤ –ø–∞–ø–∫—É best_models
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤ –≤ –ø–∞–ø–∫—É best_models
            with open(os.path.join(self.save_dir, 'best_model_threshold_analysis.json'), 'w') as f:
                json.dump(threshold_analysis, f, indent=2)
            
            # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model_summary = self._create_best_model_summary(
                threshold_analysis, 
                metrics or {}, 
                roc_auc, 
                step
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            with open(os.path.join(self.save_dir, 'best_model_evaluation_summary.json'), 'w') as f:
                json.dump(best_model_summary, f, indent=2)
            
            print(f"üìä –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {self.save_dir}")
            print(f"üìã –°–≤–æ–¥–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: best_model_evaluation_summary.json")
            print(f"üéØ –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏:")
            for metric, threshold in threshold_analysis['best_thresholds'].items():
                value = threshold_analysis['best_values'][metric]
                print(f"   {metric.capitalize()}: {threshold:.2f} (–∑–Ω–∞—á–µ–Ω–∏–µ: {value:.4f})")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª—è—Ö
        best_models_info = {
            'best_models': [
                {
                    'roc_auc': score,
                    'step': step,
                    'model_path': path,
                    'model_filename': os.path.basename(path)
                }
                for score, step, path in self.best_scores
            ]
        }
        
        with open(os.path.join(self.save_dir, 'best_models.json'), 'w') as f:
            json.dump(best_models_info, f, indent=2)
    
    def _create_best_model_summary(
        self, 
        threshold_analysis: Dict[str, Any], 
        metrics: Dict[str, float], 
        roc_auc: float, 
        step: int
    ) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å–≤–æ–¥–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        
        Args:
            threshold_analysis: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤
            metrics: –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
            roc_auc: ROC AUC –º–æ–¥–µ–ª–∏
            step: —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            summary: —Å–≤–æ–¥–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        """
        # –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è
        best_thresholds = threshold_analysis['best_thresholds']
        best_values = threshold_analysis['best_values']
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É –¥–ª—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        summary = {
            'best_model_info': {
                'step': int(step),
                'roc_auc': float(roc_auc),
                'timestamp': datetime.now().isoformat(),
                'model_filename': f"model_step_{step}_auc_{roc_auc:.4f}.pt"
            },
            'best_results': {
                'roc_auc': float(roc_auc),
                'best_thresholds': {
                    'accuracy': {
                        'threshold': float(best_thresholds['accuracy']),
                        'value': float(best_values['accuracy'])
                    },
                    'precision': {
                        'threshold': float(best_thresholds['precision']),
                        'value': float(best_values['precision'])
                    },
                    'recall': {
                        'threshold': float(best_thresholds['recall']),
                        'value': float(best_values['recall'])
                    },
                    'f1_score': {
                        'threshold': float(best_thresholds['f1']),
                        'value': float(best_values['f1'])
                    }
                }
            },
            'evaluation_metrics': {
                'fixed_thresholds': {
                    threshold: {
                        'accuracy': float(metrics.get(f'acc_{threshold}', 0.0)),
                        'precision': float(metrics.get(f'precision_{threshold}', 0.0)),
                        'recall': float(metrics.get(f'recall_{threshold}', 0.0)),
                        'f1_score': float(metrics.get(f'f1_{threshold}', 0.0))
                    }
                    for threshold in [0.05, 0.15, 0.25, 0.5]
                    if f'acc_{threshold}' in metrics
                }
            },
            'files_generated': {
                'model_checkpoint': f"model_step_{step}_auc_{roc_auc:.4f}.pt",
                'threshold_analysis_plot': 'best_model_threshold_analysis.png',
                'threshold_analysis_data': 'best_model_threshold_analysis.json',
                'models_list': 'best_models.json'
            }
        }
        
        return summary


def evaluate_model(
    model: CrossAttentionModel, 
    dataloader: DataLoader, 
    device: str
) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        model: –º–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        dataloader: DataLoader —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        
    Returns:
        metrics: —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for vectors_1, vectors_2, gt_matrix, dataset_name in dataloader:
            # –£–±–∏—Ä–∞–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ—Ç DataLoader
            vectors_1 = vectors_1.squeeze(0).to(device)
            vectors_2 = vectors_2.squeeze(0).to(device)
            gt_matrix = gt_matrix.squeeze(0).to(device)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            pred_matrix = model(vectors_1, vectors_2)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ target'—ã
            all_predictions.extend(pred_matrix.flatten().cpu().numpy())
            all_targets.extend(gt_matrix.flatten().cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics = {}
    
    # ROC AUC
    if len(np.unique(all_targets)) > 1:
        metrics['roc_auc'] = roc_auc_score(all_targets, all_predictions)
    else:
        metrics['roc_auc'] = 0.0
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
    for threshold in [0.05, 0.15, 0.25, 0.5]:
        pred_binary = (all_predictions > threshold).astype(int)
        
        metrics[f'acc_{threshold}'] = accuracy_score(all_targets, pred_binary)
        metrics[f'f1_{threshold}'] = f1_score(all_targets, pred_binary, zero_division=0)
        metrics[f'precision_{threshold}'] = precision_score(all_targets, pred_binary, zero_division=0)
        metrics[f'recall_{threshold}'] = recall_score(all_targets, pred_binary, zero_division=0)
    
    return metrics


def save_metrics(metrics: Dict[str, Any], filepath: str):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ JSON —Ñ–∞–π–ª"""
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    with open(filepath, 'w') as f:
        json.dump(metrics, f, indent=2)


def analyze_thresholds(
    model: CrossAttentionModel, 
    dataloader: DataLoader, 
    device: str,
    save_dir: str = None
) -> Dict[str, Any]:
    """
    –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ –æ—Ç 0.01 –¥–æ 0.60
    
    Args:
        model: –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        dataloader: DataLoader —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        save_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        
    Returns:
        analysis: —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å –ª—É—á—à–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏
    """
    model.eval()
    
    all_predictions = []
    all_targets = []
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    with torch.no_grad():
        for vectors_1, vectors_2, gt_matrix, dataset_name in dataloader:
            vectors_1 = vectors_1.squeeze(0).to(device)
            vectors_2 = vectors_2.squeeze(0).to(device)
            gt_matrix = gt_matrix.squeeze(0).to(device)
            
            pred_matrix = model(vectors_1, vectors_2)
            
            all_predictions.extend(pred_matrix.flatten().cpu().numpy())
            all_targets.extend(gt_matrix.flatten().cpu().numpy())
    
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Ä–æ–≥–∏ –æ—Ç 0.01 –¥–æ 0.60 —Å —à–∞–≥–æ–º 0.01
    thresholds = np.arange(0.01, 0.61, 0.01)
    
    results = {
        'thresholds': thresholds.tolist(),
        'accuracy': [],
        'precision': [],
        'recall': [],
        'f1': []
    }
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    for threshold in thresholds:
        pred_binary = (all_predictions > threshold).astype(int)
        
        acc = accuracy_score(all_targets, pred_binary)
        prec = precision_score(all_targets, pred_binary, zero_division=0)
        rec = recall_score(all_targets, pred_binary, zero_division=0)
        f1 = f1_score(all_targets, pred_binary, zero_division=0)
        
        results['accuracy'].append(acc)
        results['precision'].append(prec)
        results['recall'].append(rec)
        results['f1'].append(f1)
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    best_thresholds = {
        'accuracy': thresholds[np.argmax(results['accuracy'])],
        'precision': thresholds[np.argmax(results['precision'])],
        'recall': thresholds[np.argmax(results['recall'])],
        'f1': thresholds[np.argmax(results['f1'])]
    }
    
    best_values = {
        'accuracy': np.max(results['accuracy']),
        'precision': np.max(results['precision']),
        'recall': np.max(results['recall']),
        'f1': np.max(results['f1'])
    }
    
    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
    if save_dir:
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.plot(thresholds, results['accuracy'], 'b-', linewidth=2)
        plt.axvline(best_thresholds['accuracy'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Accuracy (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["accuracy"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["accuracy"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Accuracy')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 2)
        plt.plot(thresholds, results['precision'], 'g-', linewidth=2)
        plt.axvline(best_thresholds['precision'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Precision (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["precision"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["precision"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Precision')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 3)
        plt.plot(thresholds, results['recall'], 'orange', linewidth=2)
        plt.axvline(best_thresholds['recall'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'Recall (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["recall"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["recall"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('Recall')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 4)
        plt.plot(thresholds, results['f1'], 'purple', linewidth=2)
        plt.axvline(best_thresholds['f1'], color='red', linestyle='--', alpha=0.7)
        plt.title(f'F1-Score (–ª—É—á—à–∏–π –ø–æ—Ä–æ–≥: {best_thresholds["f1"]:.2f}, –∑–Ω–∞—á–µ–Ω–∏–µ: {best_values["f1"]:.3f})')
        plt.xlabel('–ü–æ—Ä–æ–≥')
        plt.ylabel('F1-Score')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if 'best_models' in save_dir:
            plot_filename = 'best_model_threshold_analysis.png'
        else:
            plot_filename = 'threshold_analysis.png'
        
        plot_path = os.path.join(save_dir, plot_filename)
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"üìä –ì—Ä–∞—Ñ–∏–∫ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {plot_path}")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    analysis = {
        'threshold_analysis': results,
        'best_thresholds': best_thresholds,
        'best_values': best_values,
        'summary': {
            f'best_accuracy_threshold_{best_thresholds["accuracy"]:.2f}': best_values['accuracy'],
            f'best_precision_threshold_{best_thresholds["precision"]:.2f}': best_values['precision'],
            f'best_recall_threshold_{best_thresholds["recall"]:.2f}': best_values['recall'],
            f'best_f1_threshold_{best_thresholds["f1"]:.2f}': best_values['f1'],
        }
    }
    
    return analysis


def plot_training_curves(training_log: List[Dict], save_dir: str):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏–∑ –ª–æ–≥–∞
    
    Args:
        training_log: —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è
        save_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    """
    if not training_log:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–≥ –ø–æ —à–∞–≥–∞–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ —Ç–æ—á–µ–∫
    training_log_sorted = sorted(training_log, key=lambda x: x.get('step', 0))
    
    steps = [entry['step'] for entry in training_log_sorted]
    train_losses = [entry['train_loss'] for entry in training_log_sorted]
    
    # –î–ª—è test_loss –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –∑–∞–ø–∏—Å–∏, –≥–¥–µ –æ–Ω –µ—Å—Ç—å
    test_steps = [entry['step'] for entry in training_log_sorted if 'test_loss' in entry]
    test_losses = [entry['test_loss'] for entry in training_log_sorted if 'test_loss' in entry]
    
    plt.figure(figsize=(15, 10))
    
    # –ì—Ä–∞—Ñ–∏–∫ –ª–æ—Å—Å–æ–≤
    plt.subplot(2, 3, 1)
    plt.plot(steps, train_losses, 'b-', label='Train Loss', linewidth=2)
    if test_losses:
        plt.plot(test_steps, test_losses, 'r-', label='Test Loss', linewidth=2, marker='o', markersize=3)
    plt.title('Training and Test Loss')
    plt.xlabel('Step')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ learning rate
    if 'lr' in training_log_sorted[0]:
        lrs = [entry['lr'] for entry in training_log_sorted]
        plt.subplot(2, 3, 2)
        plt.plot(steps, lrs, 'g-', linewidth=2)
        plt.title('Learning Rate')
        plt.xlabel('Step')
        plt.ylabel('Learning Rate')
        plt.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞–∑–Ω–æ—Å—Ç–∏ –ª–æ—Å—Å–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–æ—á–µ–∫, –≥–¥–µ –µ—Å—Ç—å test_loss)
    if test_losses:
        plt.subplot(2, 3, 3)
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º train_loss –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö test_steps
        test_train_losses = []
        for test_step in test_steps:
            # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π train_loss –¥–ª—è —ç—Ç–æ–≥–æ —à–∞–≥–∞
            closest_idx = min(range(len(steps)), key=lambda i: abs(steps[i] - test_step))
            test_train_losses.append(train_losses[closest_idx])
        
        loss_diff = [abs(train - test) for train, test in zip(test_train_losses, test_losses)]
        plt.plot(test_steps, loss_diff, 'purple', linewidth=2, marker='o', markersize=3)
        plt.title('|Train Loss - Test Loss|')
        plt.xlabel('Step')
        plt.ylabel('Loss Difference')
        plt.grid(True, alpha=0.3)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–≥–ª–∞–∂–µ–Ω–Ω—ã–µ –≤–µ—Ä—Å–∏–∏ –ª–æ—Å—Å–æ–≤
    if len(steps) > 10:
        window_size = max(5, len(steps) // 20)
        
        def smooth(y, window_size):
            return np.convolve(y, np.ones(window_size), 'valid') / window_size
        
        smooth_steps = steps[window_size-1:]
        smooth_train = smooth(train_losses, window_size)
        
        plt.subplot(2, 3, 4)
        plt.plot(smooth_steps, smooth_train, 'b-', label='Smooth Train Loss', linewidth=2)
        
        if test_losses and len(test_losses) > window_size:
            smooth_test = smooth(test_losses, window_size)
            smooth_test_steps = test_steps[window_size-1:]
            plt.plot(smooth_test_steps, smooth_test, 'r-', label='Smooth Test Loss', linewidth=2, marker='o', markersize=2)
        
        plt.title(f'Smoothed Loss (window={window_size})')
        plt.xlabel('Step')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    plt.subplot(2, 3, 5)
    stats_text = f"""
    –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è:
    
    –®–∞–≥–æ–≤: {len(steps)}
    –û—Ü–µ–Ω–æ–∫ test_loss: {len(test_losses)}
    
    Train Loss:
    ‚Ä¢ –ù–∞—á–∞–ª—å–Ω—ã–π: {train_losses[0]:.4f}
    ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π: {train_losses[-1]:.4f}
    ‚Ä¢ –ú–∏–Ω–∏–º—É–º: {min(train_losses):.4f}
    ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º: {max(train_losses):.4f}
    """
    
    if test_losses:
        stats_text += f"""
    Test Loss:
    ‚Ä¢ –ù–∞—á–∞–ª—å–Ω—ã–π: {test_losses[0]:.4f}
    ‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π: {test_losses[-1]:.4f}
    ‚Ä¢ –ú–∏–Ω–∏–º—É–º: {min(test_losses):.4f}
    ‚Ä¢ –ú–∞–∫—Å–∏–º—É–º: {max(test_losses):.4f}
    """
    
    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, 
             verticalalignment='top', fontsize=10, fontfamily='monospace')
    plt.axis('off')
    
    # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    plt.subplot(2, 3, 6)
    recent_steps = steps[-min(50, len(steps)):]
    recent_train = train_losses[-min(50, len(steps)):]
    
    plt.plot(recent_steps, recent_train, 'b-', label='Train Loss', linewidth=2)
    
    if test_losses:
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ test_loss —Ç–æ—á–∫–∏
        recent_test_count = min(50, len(test_losses))
        recent_test_steps = test_steps[-recent_test_count:]
        recent_test_losses = test_losses[-recent_test_count:]
        
        plt.plot(recent_test_steps, recent_test_losses, 'r-', label='Test Loss', linewidth=2, marker='o', markersize=3)
    
    plt.title('Recent Loss (last 50 steps)')
    plt.xlabel('Step')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plot_path = os.path.join(save_dir, 'training_curves.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"üìà –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot_path}")
    print(f"   ‚Ä¢ Train Loss: {len(steps)} —Ç–æ—á–µ–∫")
    print(f"   ‚Ä¢ Test Loss: {len(test_losses)} —Ç–æ—á–µ–∫")


def plot_metrics_curves(metrics_files: List[str], save_dir: str):
    """
    –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –º–µ—Ç—Ä–∏–∫ –∏–∑ —Ñ–∞–π–ª–æ–≤
    
    Args:
        metrics_files: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –º–µ—Ç—Ä–∏–∫
        save_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    if not metrics_files:
        print("‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏
    all_metrics = []
    for file_path in metrics_files:
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                metrics = json.load(f)
                all_metrics.append(metrics)
    
    if not all_metrics:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã –º–µ—Ç—Ä–∏–∫")
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —à–∞–≥–∞–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞ —Ç–æ—á–µ–∫
    all_metrics.sort(key=lambda x: x.get('step', 0))
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    steps = [m['step'] for m in all_metrics if 'step' in m]
    roc_aucs = [m['roc_auc'] for m in all_metrics if 'roc_auc' in m]
    
    if not steps or not roc_aucs:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –º–µ—Ç—Ä–∏–∫")
        return
    
    # –ì—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
    thresholds = [0.05, 0.15, 0.25, 0.5]
    
    plt.figure(figsize=(15, 10))
    
    # ROC AUC
    plt.subplot(2, 3, 1)
    plt.plot(steps, roc_aucs, 'b-', linewidth=2, marker='o')
    plt.title('ROC AUC')
    plt.xlabel('Step')
    plt.ylabel('ROC AUC')
    plt.grid(True, alpha=0.3)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    for i, threshold in enumerate(thresholds):
        acc_key = f'acc_{threshold}'
        f1_key = f'f1_{threshold}'
        
        if all(acc_key in m for m in all_metrics):
            accs = [m[acc_key] for m in all_metrics]
            plt.subplot(2, 3, i+2)
            plt.plot(steps, accs, 'g-', linewidth=2, marker='o', label='Accuracy')
            
            if all(f1_key in m for m in all_metrics):
                f1s = [m[f1_key] for m in all_metrics]
                plt.plot(steps, f1s, 'r-', linewidth=2, marker='s', label='F1')
            
            plt.title(f'Threshold {threshold}')
            plt.xlabel('Step')
            plt.ylabel('Score')
            plt.legend()
            plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plot_path = os.path.join(save_dir, 'metrics_curves.png')
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"üìä –ì—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {plot_path}")


def train_cross_attention_model(
    model: CrossAttentionModel,
    train_dataset: CrossAttentionDataset,
    test_dataset: CrossAttentionDataset,
    num_epochs: int = 10,
    learning_rate: float = 1e-4,
    device: str = "auto",
    save_dir: str = "./checkpoints",
    eval_every_steps: int = 100,
    save_metrics_every_steps: int = 50,
    batch_size: int = 1,
    num_workers: int = 0,
    max_steps: int = None
):
    """
    –û–±—É—á–µ–Ω–∏–µ Cross-Attention –º–æ–¥–µ–ª–∏
    
    Args:
        model: –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        train_dataset: —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        test_dataset: —Ç–µ—Å—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç
        num_epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
        learning_rate: —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        save_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        eval_every_steps: —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        save_metrics_every_steps: —á–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è DataLoader
        num_workers: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers –¥–ª—è DataLoader
    """
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logger = setup_logging(os.path.join(save_dir, "logs"))
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    
    model = model.to(device)
    
    # –°–æ–∑–¥–∞–µ–º DataLoaders
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True if device == "cuda" else False
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True if device == "cuda" else False
    )
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)
    
    # –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
    total_steps = len(train_loader) * num_epochs
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_steps)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
    model_saver = BestModelSaver(
        os.path.join(save_dir, "best_models"), 
        keep_top_k=2,
        test_loader=test_loader,
        device=device
    )
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    results_dir = save_dir  # –ì–ª–∞–≤–Ω–∞—è –ø–∞–ø–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    metrics_dir = os.path.join(save_dir, "metrics")  # –ü–æ–¥–ø–∞–ø–∫–∞ –¥–ª—è JSON —Ñ–∞–π–ª–æ–≤
    os.makedirs(results_dir, exist_ok=True)
    os.makedirs(metrics_dir, exist_ok=True)
    
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è:")
    logger.info(f"   –≠–ø–æ—Ö–∏: {num_epochs}")
    logger.info(f"   –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: {len(train_loader)}")
    logger.info(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {total_steps}")
    logger.info(f"   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    logger.info(f"   Learning rate: {learning_rate}")
    logger.info(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results_dir}")
    logger.info(f"   –ú–µ—Ç—Ä–∏–∫–∏: {metrics_dir}")
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    training_log = []
    step_counter = 0
    best_roc_auc = 0.0
    
    start_time = time.time()
    
    for epoch in range(num_epochs):
        model.train()
        epoch_loss = 0.0
        
        for batch_idx, (vectors_1, vectors_2, gt_matrix, dataset_name) in enumerate(train_loader):
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            vectors_1 = vectors_1.squeeze(0).to(device)  # –£–±–∏—Ä–∞–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –æ—Ç DataLoader
            vectors_2 = vectors_2.squeeze(0).to(device)
            gt_matrix = gt_matrix.squeeze(0).to(device)
            
            # Forward pass
            pred_matrix = model(vectors_1, vectors_2)
            
            # Loss
            loss = weighted_bce_loss(pred_matrix, gt_matrix)
            
            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()
            
            epoch_loss += loss.item()
            step_counter += 1
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
            basic_log_entry = {
                'step': step_counter,
                'epoch': epoch,
                'batch': batch_idx,
                'train_loss': loss.item(),
                'lr': scheduler.get_last_lr()[0],
                'dataset': dataset_name,
                'timestamp': datetime.now().isoformat()
            }
            training_log.append(basic_log_entry)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ max_steps
            if max_steps is not None and step_counter >= max_steps:
                logger.info(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {max_steps}")
                break
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏, –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ training_log)
            if step_counter % save_metrics_every_steps == 0:
                log_message = (f"–®–∞–≥ {step_counter:5d} | –≠–ø–æ—Ö–∞ {epoch+1:2d}/{num_epochs} | "
                              f"Train Loss: {loss.item():.4f} | "
                              f"LR: {scheduler.get_last_lr()[0]:.6f} | Dataset: {dataset_name}")
                logger.info(log_message)
            
            # –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤
            if step_counter % eval_every_steps == 0:
                logger.info(f"\nüìä –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ —à–∞–≥–µ {step_counter}...")
                
                # –ë—ã—Å—Ç—Ä—ã–π test_loss –¥–ª—è training_curves
                model.eval()
                with torch.no_grad():
                    test_vectors_1, test_vectors_2, test_gt_matrix, test_dataset_name = next(iter(test_loader))
                    test_vectors_1 = test_vectors_1.squeeze(0).to(device)
                    test_vectors_2 = test_vectors_2.squeeze(0).to(device)
                    test_gt_matrix = test_gt_matrix.squeeze(0).to(device)
                    
                    test_pred_matrix = model(test_vectors_1, test_vectors_2)
                    test_loss_for_curves = weighted_bce_loss(test_pred_matrix, test_gt_matrix)
                
                # –î–æ–±–∞–≤–ª—è–µ–º test_loss –∫ —Ç–µ–∫—É—â–µ–π –∑–∞–ø–∏—Å–∏ –≤ training_log
                training_log[-1]['test_loss'] = test_loss_for_curves.item()
                
                # –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫
                metrics = evaluate_model(model, test_loader, device)
                
                logger.info(f"üéØ –ú–µ—Ç—Ä–∏–∫–∏:")
                logger.info(f"   ROC AUC: {metrics['roc_auc']:.4f}")
                for threshold in [0.05, 0.15, 0.25, 0.5]:
                    threshold_msg = (f"   –ü–æ—Ä–æ–≥ {threshold}: Acc={metrics[f'acc_{threshold}']:.3f}, "
                                   f"F1={metrics[f'f1_{threshold}']:.3f}, "
                                   f"Prec={metrics[f'precision_{threshold}']:.3f}, "
                                   f"Rec={metrics[f'recall_{threshold}']:.3f}")
                    logger.info(threshold_msg)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ –ø–æ–¥–ø–∞–ø–∫—É metrics/
                metrics['step'] = step_counter
                metrics['epoch'] = epoch
                save_metrics(metrics, f"{metrics_dir}/metrics_step_{step_counter}.json")
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π
                current_roc_auc = metrics['roc_auc']
                if current_roc_auc > best_roc_auc:
                    best_roc_auc = current_roc_auc
                    model_saver.save_if_best(model, current_roc_auc, step_counter, metrics)
                
                model.train()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
                logger.info("")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ max_steps –¥–ª—è –≤—ã—Ö–æ–¥–∞ –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ —ç–ø–æ—Ö–∞–º
        if max_steps is not None and step_counter >= max_steps:
            logger.info(f"üõë –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è - –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: {max_steps}")
            break
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —ç–ø–æ—Ö–∏
        avg_epoch_loss = epoch_loss / len(train_loader)
        elapsed_time = time.time() - start_time
        
        logger.info(f"\nüìà –≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs} –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        logger.info(f"   –°—Ä–µ–¥–Ω–∏–π loss: {avg_epoch_loss:.4f}")
        logger.info(f"   –í—Ä–µ–º—è: {elapsed_time/60:.1f} –º–∏–Ω")
        logger.info(f"   –õ—É—á—à–∏–π ROC AUC: {best_roc_auc:.4f}")
        logger.info("-" * 60)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ –æ–±—É—á–µ–Ω–∏—è –≤ –ø–æ–¥–ø–∞–ø–∫—É metrics/
    with open(f"{metrics_dir}/training_log.json", 'w') as f:
        json.dump(training_log, f, indent=2)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥–ª–∞–≤–Ω—É—é –ø–∞–ø–∫—É)
    logger.info(f"\nüìà –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è...")
    plot_training_curves(training_log, results_dir)
    
    # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –º–µ—Ç—Ä–∏–∫ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –≥–ª–∞–≤–Ω—É—é –ø–∞–ø–∫—É)
    metrics_files = [f for f in os.listdir(metrics_dir) if f.startswith('metrics_step_') and f.endswith('.json')]
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –Ω–æ–º–µ—Ä—É —à–∞–≥–∞, –∞ –Ω–µ –ø–æ —Å—Ç—Ä–æ–∫–µ
    def extract_step_from_filename(filename):
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ "metrics_step_123.json"
            step_str = filename.replace('metrics_step_', '').replace('.json', '')
            return int(step_str)
        except ValueError:
            return 0
    
    metrics_files.sort(key=extract_step_from_filename)
    metrics_files = [os.path.join(metrics_dir, f) for f in metrics_files]
    if metrics_files:
        plot_metrics_curves(metrics_files, results_dir)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    logger.info(f"\nüèÅ –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞...")
    final_metrics = evaluate_model(model, test_loader, device)
    save_metrics(final_metrics, f"{metrics_dir}/final_metrics.json")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ (–≥—Ä–∞—Ñ–∏–∫ –≤ –≥–ª–∞–≤–Ω—É—é –ø–∞–ø–∫—É, JSON –≤ metrics/)
    logger.info(f"\nüîç –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤ (0.01 - 0.60)...")
    threshold_analysis = analyze_thresholds(model, test_loader, device, results_dir)
    save_metrics(threshold_analysis, f"{metrics_dir}/threshold_analysis.json")
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤
    logger.info(f"üìä –õ—É—á—à–∏–µ –ø–æ—Ä–æ–≥–∏:")
    for metric, threshold in threshold_analysis['best_thresholds'].items():
        value = threshold_analysis['best_values'][metric]
        logger.info(f"   {metric.capitalize()}: {threshold:.2f} (–∑–Ω–∞—á–µ–Ω–∏–µ: {value:.4f})")
    
    logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    logger.info(f"   –§–∏–Ω–∞–ª—å–Ω—ã–π ROC AUC: {final_metrics['roc_auc']:.4f}")
    logger.info(f"   –õ—É—á—à–∏–π ROC AUC: {best_roc_auc:.4f}")
    logger.info(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {(time.time() - start_time)/60:.1f} –º–∏–Ω")
    logger.info(f"   üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤:")
    logger.info(f"      üìä –ì—Ä–∞—Ñ–∏–∫–∏: {results_dir}/*.png")
    logger.info(f"      üìã –ú–µ—Ç—Ä–∏–∫–∏: {metrics_dir}/*.json")
    
    return model, training_log, final_metrics, threshold_analysis


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Cross-Attention Model Training")
    parser.add_argument("--entities_path", type=str, required=True, help="Path to entities JSON file")
    parser.add_argument("--relations_path", type=str, required=True, help="Path to relations JSON file")
    parser.add_argument("--output_dir", type=str, required=True, help="Output directory")
    parser.add_argument("--dataset_name", type=str, required=True, help="Dataset name")
    parser.add_argument("--epochs", type=int, default=10, help="Number of epochs")
    parser.add_argument("--batch_size", type=int, default=32, help="Batch size")
    parser.add_argument("--eval_every", type=int, default=10, help="Evaluate every N steps")
    parser.add_argument("--save_every", type=int, default=50, help="Save every N steps")
    parser.add_argument("--lr", type=float, default=1e-4, help="Learning rate")
    parser.add_argument("--test_size", type=float, default=0.2, help="Test split size")
    parser.add_argument("--max_steps", type=int, default=None, help="Maximum training steps")
    parser.add_argument("--seed", type=int, default=42, help="Random seed for reproducibility")
    parser.add_argument("--use_qwen3", action="store_true", help="Initialize from Qwen3")
    parser.add_argument("--qwen3_model", type=str, default="Qwen/Qwen3-4B", help="Qwen3 model name")
    parser.add_argument("--dataset_strategy", type=str, default="single", choices=["single", "weighted"], help="Dataset selection strategy")
    parser.add_argument("--sampling_strategy", type=str, default="balanced", choices=["random", "balanced"], help="Entity sampling strategy within dataset")
    parser.add_argument("--positive_ratio", type=float, default=1.0, help="Ratio of positive pairs for balanced sampling (1.0 = maximum possible)")
    parser.add_argument("--log_level", type=str, default="INFO", choices=["DEBUG", "INFO", "WARNING", "ERROR"], help="Logging level")
    parser.add_argument("--num_attention_heads", type=int, default=8, help="Number of attention heads")
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    experiment_name = create_experiment_name(args)
    experiment_dir = os.path.join(args.output_dir, experiment_name)
    os.makedirs(experiment_dir, exist_ok=True)
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
    logger = setup_logging(experiment_dir, args.log_level)
    
    logger.info(f"üöÄ –ù–∞—á–∞–ª–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_name}")
    logger.info(f"üìÅ –ü–∞–ø–∫–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞: {experiment_dir}")
    logger.info(f"üé≤ Seed: {args.seed}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º seed
    logger.info(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    logger.info(f"   Entities: {args.entities_path}")
    logger.info(f"   Relations: {args.relations_path}")
    
    train_dataset, test_dataset = create_train_test_datasets(
        args.entities_path,
        args.relations_path,
        batch_size_1=args.batch_size,
        batch_size_2=args.batch_size,
        dataset_strategy=args.dataset_strategy,
        sampling_strategy=args.sampling_strategy,
        positive_ratio=args.positive_ratio,
        test_part=args.test_size,
        random_state=args.seed  # –§–∏–∫—Å–∏—Ä—É–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    )
    
    logger.info(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç—ã —Å–æ–∑–¥–∞–Ω—ã: Train={len(train_dataset)}, Test={len(test_dataset)}")
    
    # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
    if args.use_qwen3:
        logger.info(f"üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑ Qwen3: {args.qwen3_model}")
        model = initialize_from_qwen3(args.qwen3_model)
    else:
        logger.info(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏)
        test_config = {
            'hidden_size': 2560,  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
            'num_attention_heads': args.num_attention_heads,
            'num_key_value_heads': args.num_attention_heads,
            'rms_norm_eps': 1e-6,
            'attention_bias': False
        }
        model = CrossAttentionModel(test_config)
    
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {model}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤ —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    logger.info(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    trained_model, training_log, final_metrics, threshold_analysis = train_cross_attention_model(
        model=model,
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        num_epochs=args.epochs,
        learning_rate=args.lr,
        save_dir=experiment_dir,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        eval_every_steps=args.eval_every,
        save_metrics_every_steps=args.save_every,
        batch_size=1,  # DataLoader batch size (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π batch —Ä–∞–∑–º–µ—Ä —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º)
        num_workers=0,
        max_steps=args.max_steps
    )
    
    # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –≥–ª–∞–≤–Ω–æ–π –ø–∞–ø–∫–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    logger.info(f"\nüìã –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π —Å–≤–æ–¥–∫–∏...")
    create_best_results_summary(
        threshold_analysis,
        final_metrics,
        training_log,
        args,
        os.path.join(experiment_dir, "best_results.json")
    )
    
    logger.info(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {experiment_dir}")
    logger.info(f"   üìä –ì—Ä–∞—Ñ–∏–∫–∏: training_curves.png, metrics_curves.png, threshold_analysis.png")
    logger.info(f"   üìã –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞: best_results.json")
    logger.info(f"   üìÇ –î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: metrics/")
    logger.info(f"   üèÜ –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏: best_models/ (–≤–∫–ª—é—á–∞—è –∞–Ω–∞–ª–∏–∑ –ø–æ—Ä–æ–≥–æ–≤)")
    logger.info(f"       ‚Ä¢ best_models.json")
    logger.info(f"       ‚Ä¢ best_model_threshold_analysis.json")
    logger.info(f"       ‚Ä¢ best_model_threshold_analysis.png")
    logger.info(f"       ‚Ä¢ best_model_evaluation_summary.json")
    